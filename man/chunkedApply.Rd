% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{chunkedApply}
\alias{chunkedApply}
\title{Reads chunks of data from a memory-mapped file into memory and applies a
function on each row or column of a matrix in parallel.}
\usage{
chunkedApply(X, MARGIN, FUN, i = seq_len(nrow(X)), j = seq_len(ncol(X)),
  bufferSize = NULL, nBuffers = NULL, nTasks = nCores, nCores = 1,
  verbose = FALSE, ...)
}
\arguments{
\item{X}{A matrix-like object, typically \code{@geno} of a
\code{\link[=BGData-class]{BGData}} object.}

\item{MARGIN}{The subscripts which the function will be applied over. 1
indicates rows, 2 indicates columns.}

\item{FUN}{The function to be applied.}

\item{i}{(integer, boolean or character) Indicates which rows should be used.
By default, all rows are used.}

\item{j}{(integer, boolean or character) Indicates which columns should be
used. By default, all columns are used.}

\item{bufferSize}{The number of rows or columns of \code{X} that are brought
into RAM for processing. Overwrites \code{nBuffers}. If both parameters are
\code{NULL}, all elements in \code{i} or \code{j} are used.}

\item{nBuffers}{The number of partitions of the rows or columns of \code{X}
that are brought into RAM for processing. Is overwritten by
\code{bufferSize}. If both parameters are \code{NULL}, all elements in
\code{i} or \code{j} are used.}

\item{nTasks}{The number of submatrices of each buffered subset of \code{X}
to be processed in parallel.}

\item{nCores}{The number of cores (passed to
\code{\link[parallel]{mclapply}}).}

\item{verbose}{Whether to print additional information.}

\item{...}{Additional arguments to be passed to \code{parallelApply}.}
}
\description{
\code{bufferSize} and \code{nTasks} have to be chosen carefully to avoid
running out of memory. As a rule of thumb, at least around
\code{object_size(buffer) + (nCores * (object_size(buffer) / nTasks)) +
object_size(result)} MB of total memory will be needed, not including
potential copies of your data that might be created (for example \code{lsfit}
runs \code{cbind(1, X)}). Therefore, for 20 nodes and 20 tasks you will need
at least \code{2 * object_size(buffer)} MB, for 20 nodes and 40 tasks
\code{1.5 * object_size(buffer)} MB, etc.
}
\details{
This function is only useful for memory-mapped files. For data that is
already in memory, use \code{\link{parallelApply}} directly.
}

